{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b90fa82a58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index=7777 #You may select anything upto 60,000\n",
    "print(y_train[image_index]) #The label is 8\n",
    "plt.imshow(x_train[image_index],cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "#Reshaping the array to 4-dims so that it can work with Keras API\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28,1)\n",
    "input_shape=(28,28,1)\n",
    "#Making sure that values are float so that we can get decimal point after dividing\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "#Normalising the RGB codes by dividing into max RGB value\n",
    "x_train/=255 #Dividing by 255 to map it to max RGB Nos. as there as 255 colors b/w R to B\n",
    "x_test/=255\n",
    "print('x_train shape:',x_train.shape)\n",
    "print('Number of images in x_train',x_train.shape[0])\n",
    "print('Number of images in x_test',x_test.shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a sequential model and adding the layers\n",
    "model=Sequential()\n",
    "model.add(Conv2D(28,kernel_size=(3,3),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten()) #Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128,activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dropout in module keras.layers.core:\n",
      "\n",
      "class Dropout(keras.engine.base_layer.Layer)\n",
      " |  Applies Dropout to the input.\n",
      " |  \n",
      " |  Dropout consists in randomly setting\n",
      " |  a fraction `rate` of input units to 0 at each update during training time,\n",
      " |  which helps prevent overfitting.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      rate: float between 0 and 1. Fraction of the input units to drop.\n",
      " |      noise_shape: 1D integer tensor representing the shape of the\n",
      " |          binary dropout mask that will be multiplied with the input.\n",
      " |          For instance, if your inputs have shape\n",
      " |          `(batch_size, timesteps, features)` and\n",
      " |          you want the dropout mask to be the same for all timesteps,\n",
      " |          you can use `noise_shape=(batch_size, 1, features)`.\n",
      " |      seed: A Python integer to use as random seed.\n",
      " |  \n",
      " |  # References\n",
      " |      - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting]\n",
      " |        (http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dropout\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, rate, noise_shape=None, seed=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  call(self, inputs, training=None)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.1970 - acc: 0.9404\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0802 - acc: 0.9757\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0553 - acc: 0.9827\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0411 - acc: 0.9869\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0334 - acc: 0.9890\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0276 - acc: 0.9908\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 170s 3ms/step - loss: 0.0242 - acc: 0.9919 8s - loss: 0.\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0211 - acc: 0.9925\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 170s 3ms/step - loss: 0.0176 - acc: 0.9940\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0182 - acc: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b90fab3c50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 17s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06897964853864233, 0.9837]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index=22\n",
    "plt.imshow(x_test[image_index].reshape(28,28),cmap='Greys')\n",
    "pred=model.predict(x_test[image_index].reshape(1,28,28,1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
